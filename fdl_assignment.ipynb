{
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o3QK7dhJRKmH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "vscode": {
      "interpreter": {
        "hash": "d8a1dba90a7a3c73ffa205c3fa0146003aed819f1f43d631078b51d929ccab9c"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrienloizeau/cifar-pytorch-model-/blob/main/fdl_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FDL- DSBA Assignment 2022-2023\n",
        "\n",
        "### Please fill the blanks in the code and answer to the questions that are asked in the Jupyter Notebook (\"Markdown\" cell). \n",
        "\n",
        "### Instructions: Rename the jupyter adding your name at the end of the title FDL_Assignment-<YOUR NAME\\>.ipynb\n",
        "\n",
        "### Upload your solution on Edunao before the 19/12/2022 (December the 12th), and set the file name to FDL_Assignment-<YOUR NAME\\>\n",
        "\n",
        "For any questions, please contact Arthur Ledaguenel at arthur.ledaguenel@centralesupelec.fr and put \\[FDL\\] in the object of the mail"
      ],
      "metadata": {
        "id": "HzT-fZzFRKly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 -  TRAIN ON CIFAR DATASET\n",
        "In this exercise you are asked to train a Convolutional Neural Network (CNN) on the CIFAR10 dataset and visualize its feature maps."
      ],
      "metadata": {
        "id": "zPUOV6dFRKl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1a) Download the CIFAR10 dataset using the already provided PyTorch dataloaders. \n",
        "*   Read and understand the following code\n",
        "*   Feel free to add additional transformations of data. Explain if so. "
      ],
      "metadata": {
        "id": "lCX0xLejRKl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "31bJgkWSUt8u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Download the CIFAR10 dataset using the PyTorch dataloaders\n",
        "import json \n",
        "from pprint import pprint\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# *****START CODE \n",
        "## Data\n",
        "##Here you are free to add further transform functions if you wish\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    transforms.RandomVerticalFlip([0.3])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    transforms.RandomVerticalFlip([0.3])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size= batch_size , shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "val_dataloader = torch.utils.data.DataLoader(testset, batch_size= batch_size, shuffle=False)\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "5KyVunArRKl-",
        "outputId": "32ab8f9f-260a-4266-9728-294f53ba196f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:29.144140Z",
          "iopub.execute_input": "2022-12-14T15:04:29.144487Z",
          "iopub.status.idle": "2022-12-14T15:04:30.820640Z",
          "shell.execute_reply.started": "2022-12-14T15:04:29.144458Z",
          "shell.execute_reply": "2022-12-14T15:04:30.819654Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b) Create your convolutional neural network.\n",
        "*   Go to https://dljudge.io/generate + /<YOUR NAME\\> or use curl below\n",
        "*   Save the page as json \n",
        "*   Build your CNN architecture based on those modules and hyperparameters\n",
        "*   Use the right value for 'COMPUTE' \n",
        "*   See the example below"
      ],
      "metadata": {
        "id": "3S-ITJo9RKmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://dljudge.io/generate/adrienloizeau -o network1.json"
      ],
      "metadata": {
        "id": "gnmWWieDVm-g",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:30.822377Z",
          "iopub.execute_input": "2022-12-14T15:04:30.823081Z",
          "iopub.status.idle": "2022-12-14T15:04:31.894808Z",
          "shell.execute_reply.started": "2022-12-14T15:04:30.823040Z",
          "shell.execute_reply": "2022-12-14T15:04:31.893610Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7de75a-3f36-43da-bda6-d112ab9f4899"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2038  100  2038    0     0  21229      0 --:--:-- --:--:-- --:--:-- 21229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_network(model, input_dict):\n",
        "    \"\"\"\n",
        "    Validate if your network definition is same as provided architecture\n",
        "    \"\"\"\n",
        "    output = {}\n",
        "    i = 1\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'Conv2d',\n",
        "                                                  'kernel_size': layer.kernel_size[0],\n",
        "                                                   'input': layer.in_channels,\n",
        "                                                   'output': layer.out_channels,\n",
        "                                                   'padding': layer.padding[0]}\n",
        "\n",
        "        if isinstance(layer, nn.ReLU):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'ReLU'}\n",
        "\n",
        "        if isinstance(layer, nn.MaxPool2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'MaxPool2d',\n",
        "                                                  'kernel_size': layer.kernel_size,\n",
        "                                                  'stride': layer.stride}\n",
        "\n",
        "        if isinstance(layer, nn.AdaptiveAvgPool2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'AdaptiveAvgPool2d',\n",
        "                                                  'output': layer.output_size}\n",
        "\n",
        "        if isinstance(layer, nn.BatchNorm2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'BatchNorm2d',\n",
        "                                                  'input': layer.num_features}\n",
        "\n",
        "        if isinstance(layer, nn.Dropout):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'Dropout',\n",
        "                                                  'p': layer.p}\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'Linear',\n",
        "                                                  'input': layer.in_features,\n",
        "                                                  'output': layer.out_features}\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    \n",
        "    correct = True\n",
        "    for l in output.keys():\n",
        "        if l in input_dict:\n",
        "            inp_kvs = input_dict[l]\n",
        "            out_kvs = output[l]\n",
        "            for k in out_kvs:\n",
        "                if inp_kvs[k] != 'COMPUTE':\n",
        "                    if out_kvs[k] != inp_kvs[k]:\n",
        "                        print(out_kvs[k])\n",
        "                        print (f'Error in {l}, {k}!')\n",
        "                        correct = False\n",
        "\n",
        "    if correct:\n",
        "        print ('OK!')"
      ],
      "metadata": {
        "id": "fut0mqaSVm-g",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:31.897452Z",
          "iopub.execute_input": "2022-12-14T15:04:31.897880Z",
          "iopub.status.idle": "2022-12-14T15:04:31.910698Z",
          "shell.execute_reply.started": "2022-12-14T15:04:31.897825Z",
          "shell.execute_reply": "2022-12-14T15:04:31.909659Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE \n",
        "# Import your individual architecture dictionnary here\n",
        "#fin = open('CNN.json', 'r')\n",
        "#my_architecture_dict = json.load(fin)\n",
        "#fin.close()\n",
        "\n",
        "#pprint(my_architecture_dict)\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "hiihuvTRVm-h",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:32.505968Z",
          "iopub.execute_input": "2022-12-14T15:04:32.506314Z",
          "iopub.status.idle": "2022-12-14T15:04:32.516331Z",
          "shell.execute_reply.started": "2022-12-14T15:04:32.506284Z",
          "shell.execute_reply": "2022-12-14T15:04:32.515318Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the model"
      ],
      "metadata": {
        "id": "H0GdydoAakXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# *****START CODE\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, inplanes :int, planes : int, stride = 1, downsample = None, \n",
        "                 groups = 1, base_width = 64, dilation = 1, norm_layer = None, nb_labels = 16):\n",
        "        super(ConvNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        # ? \n",
        "        # width = int(planes * (base_width / 64.0)) * groups\n",
        "\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "\n",
        "        self.conv1  = nn.Conv2d(width,56,3,padding  = 1)\n",
        "        self.batch1 =nn.BatchNorm2d(56)\n",
        "\n",
        "        self.relu1  = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv2  = nn.Conv2d(56,135,3,padding  = 1)\n",
        "        self.batch2 =nn.BatchNorm2d(135)\n",
        "\n",
        "        self.relu2  = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.conv3  = nn.Conv2d(135,246,3,padding  = 1)\n",
        "        self.batch3 =nn.BatchNorm2d(246)\n",
        "        \n",
        "        self.relu3  = nn.ReLU()\n",
        "        self.conv4  = nn.Conv2d(246,246,3,padding  = 1)\n",
        "        \n",
        "        self.batch4 =nn.BatchNorm2d(246)\n",
        "        self.relu4  = nn.ReLU()\n",
        "        #10 \n",
        "        \n",
        "        self.maxpool3 = nn.MaxPool2d(2,2)\n",
        "        self.conv5  = nn.Conv2d(246,520,3,padding  = 1)\n",
        "        \n",
        "        self.batch5 =nn.BatchNorm2d(520)\n",
        "        self.relu5  = nn.ReLU()\n",
        "        \n",
        "        self.conv6  = nn.Conv2d(520,520,3,padding  = 1)\n",
        "        self.batch6 =nn.BatchNorm2d(520)\n",
        "\n",
        "        self.relu6  = nn.ReLU()\n",
        "        self.maxpool4 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.conv7  = nn.Conv2d(520,520,3,padding  = 1)\n",
        "        self.batch7 = nn.BatchNorm2d(520)\n",
        "        \n",
        "        self.relu7  = nn.ReLU()\n",
        "        self.conv8  = nn.Conv2d(520,520,3,padding  = 1)\n",
        "        \n",
        "        self.batch8 = nn.BatchNorm2d(520)\n",
        "        self.relu8  = nn.ReLU()\n",
        "        \n",
        "        self.maxpool5 = nn.MaxPool2d(2,2)\n",
        "        # Compute here set to 520 to fit the previous modules. \n",
        "        # AdaptiveAvgPool2d makes an average pooling\n",
        "        self.adapt1 = nn.AdaptiveAvgPool2d(1)\n",
        "        \n",
        "        # Does not modify the size \n",
        "        self.dropout1 = nn.Dropout(p=0.5112472379693787)\n",
        "        # We still are only with 520\n",
        "        self.linear1 = nn.Linear(520, 2142)\n",
        "        \n",
        "        self.relu9 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(p=0.5112472379693787)\n",
        "        \n",
        "        self.linear2 = nn.Linear(2142,3067)\n",
        "        self.relu10 = nn.ReLU()\n",
        "\n",
        "        self.dropout3 = nn.Dropout(p=0.5112472379693787)\n",
        "        self.linear3 = nn.Linear(3067,3922)\n",
        "        \n",
        "        self.relu11 = nn.ReLU()\n",
        "        \n",
        "        self.linear4 = nn.Linear(3922,nb_labels * planes)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        x = self.batch2(x)\n",
        "        x = self.relu2(x)\n",
        "        \n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x = self.batch3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batch4(x)\n",
        "        \n",
        "        x = self.relu4(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batch5(x)\n",
        "        \n",
        "        x = self.relu5(x)\n",
        "        x = self.conv6(x)\n",
        "        \n",
        "        x = self.batch6(x)\n",
        "        x = self.relu6(x)\n",
        "        \n",
        "        x = self.maxpool4(x)\n",
        "        x = self.conv7(x)\n",
        "\n",
        "        x = self.batch7(x)\n",
        "        x = self.relu7(x)\n",
        "        \n",
        "        x = self.conv8(x)\n",
        "        x = self.batch8(x)\n",
        "\n",
        "        \n",
        "        x = self.relu8(x)\n",
        "        x = self.maxpool5(x)\n",
        "        \n",
        "        x = self.adapt1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.linear1(x)\n",
        "        x = self.relu9(x)\n",
        "\n",
        "        x = self.dropout2(x)\n",
        "        x = self.linear2(x)\n",
        "        \n",
        "        x = self.relu10(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.linear3(x)\n",
        "        x = self.relu11(x)\n",
        "\n",
        "        x = self.linear4(x)\n",
        "        return x\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "9hb1skoXRKmA",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:33.105546Z",
          "iopub.execute_input": "2022-12-14T15:04:33.106906Z",
          "iopub.status.idle": "2022-12-14T15:04:33.128005Z",
          "shell.execute_reply.started": "2022-12-14T15:04:33.106860Z",
          "shell.execute_reply": "2022-12-14T15:04:33.126969Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1c) Create the training scheme\n",
        "*    Initialize the model\n",
        "*    Validate the model\n",
        "*    Specify the training hyperparameters like type of optimizer, criterion and learning rate\n",
        "*    Specify number of epochs\n",
        "*    Connect the model and any further informations to WandB\n",
        "\n",
        "Then train the model, doing one evaluation pass per epoch (make sure to log any interesting metric to WandB during training)."
      ],
      "metadata": {
        "id": "1oCW4FGORKmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing wandb"
      ],
      "metadata": {
        "id": "IYf6_blAW26z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet\n",
        "\n",
        "# Import the library\n",
        "import wandb\n",
        "# Then connect to your W&B account\n",
        "def wandb_connect():\n",
        "    wandb_api_key_label = \"\"\n",
        "    wandb_api_key = \"77e0a94a0fa993f825495a3021ebfa5477225ce9\" # here use your API key from WandB interface\n",
        "\n",
        "    wandb_conx = wandb.login(key = wandb_api_key)\n",
        "    print(f\"Connected to Wandb online interface : {wandb_conx}\")\n",
        "\n",
        "wandb_connect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsIk7NZCxeVO",
        "outputId": "a63cea5a-3cb5-4050-81e0-6d0529352a0a",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:34.726659Z",
          "iopub.execute_input": "2022-12-14T15:04:34.727535Z",
          "iopub.status.idle": "2022-12-14T15:04:44.377813Z",
          "shell.execute_reply.started": "2022-12-14T15:04:34.727496Z",
          "shell.execute_reply": "2022-12-14T15:04:44.376661Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madrienloizeau\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to Wandb online interface : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report "
      ],
      "metadata": {
        "id": "aCYRCk_HRoe-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring data before training"
      ],
      "metadata": {
        "id": "-j4WwxfJLPX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "batch_size= 64\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "# get some random training images\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:53.701543Z",
          "iopub.execute_input": "2022-12-14T15:04:53.701973Z",
          "iopub.status.idle": "2022-12-14T15:04:53.953799Z",
          "shell.execute_reply.started": "2022-12-14T15:04:53.701931Z",
          "shell.execute_reply": "2022-12-14T15:04:53.952825Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "H8wIQB1KLPX-",
        "outputId": "59a9cb56-f760-47e5-896f-212e46859e46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c929b11c7abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# get some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# show images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomly\u001b[0m \u001b[0mflipped\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \"\"\"\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'Tensor' and 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Back to code : defining the learning rate, optimizer and criterion"
      ],
      "metadata": {
        "id": "8xreesy0LPX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "import torch\n",
        "\n",
        "lr = 0.01\n",
        "model = ConvNet(3,3, nb_labels= 16)\n",
        "#validate_network(model, my_architecture_dict)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 1\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "emDRadjhRKmD",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:53.956301Z",
          "iopub.execute_input": "2022-12-14T15:04:53.956971Z",
          "iopub.status.idle": "2022-12-14T15:04:54.235721Z",
          "shell.execute_reply.started": "2022-12-14T15:04:53.956934Z",
          "shell.execute_reply": "2022-12-14T15:04:54.234644Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the hyperparams dict with the infos of your run\n",
        "# *****START CODE\n",
        "hyperparams = {\"Batch size\":batch_size,\n",
        "               \"Learning rate\":lr,\n",
        "               \"Epochs\":epochs}\n",
        "# *****END CODE\n",
        "\n",
        "# Init the WandB run with hyperparams\n",
        "wandb.init(config=hyperparams)"
      ],
      "metadata": {
        "id": "bNx4JHRJUl3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First training loop"
      ],
      "metadata": {
        "id": "vZfe1nY7LPYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:54.237373Z",
          "iopub.execute_input": "2022-12-14T15:04:54.237780Z",
          "iopub.status.idle": "2022-12-14T15:04:54.244433Z",
          "shell.execute_reply.started": "2022-12-14T15:04:54.237743Z",
          "shell.execute_reply": "2022-12-14T15:04:54.243366Z"
        },
        "trusted": true,
        "id": "uux0Yf09LPYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy = (TP+TN)/(TP+TN+FP+FN) # How the models performs accross all classes\n",
        "def accuracy(preds, labels):\n",
        "    return (labels==preds.cpu()).sum()/len(labels) # Argmax of logits is the argmax of the predictions (the softmax of the logits)\n",
        "\n",
        "# Precision = TP / (TP+FP) # How reliable the model is in classifying samples as Positive\n",
        "# Think about how the confusion matrix is constructed!\n",
        "def precision(cm):\n",
        "    return [col[i]/col.sum() for i, col in enumerate(cm.T)]\n",
        "\n",
        "# Recall = TP / (TP+FN)\n",
        "# Think about how the confusion matrix is constructed!\n",
        "def recall(cm):\n",
        "    return [row[i]/row.sum() for i, row in enumerate(cm)]"
      ],
      "metadata": {
        "id": "8bXhTE9IROrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def first_training_loop(model, epochs, train_dataloader, val_dataloader, optimizer, criterion, device):\n",
        "    total_train_losses = []\n",
        "    total_val_losses = []\n",
        "\n",
        "    for epoch in range(1,epochs+1):\n",
        "        print(f'epoch: {epoch}')\n",
        "        ##TRAINING##\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        trn_lbl = torch.Tensor([])\n",
        "        trn_preds = torch.Tensor([])\n",
        "        for i, batch, in enumerate(tqdm(train_dataloader)):\n",
        "            img_batch, lbl_batch = batch\n",
        "            trn_lbl=torch.cat((trn_lbl, lbl_batch))\n",
        "            img_batch, lbl_batch = img_batch.to(device), lbl_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(img_batch)\n",
        "            trn_preds=torch.cat((trn_preds, logits.argmax(1).cpu()))\n",
        "            loss=criterion(logits, lbl_batch)\n",
        "            wandb.log({\"train_loss\":loss.item()}) # log the training loss at each batch\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        train_acc=accuracy(trn_preds, trn_lbl)\n",
        "        train_loss_mean = np.mean(train_losses)\n",
        "        total_train_losses.append(train_loss_mean)\n"
      ],
      "metadata": {
        "id": "EFeNZ8aIRK60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_model(model, path):# Saving the model\n",
        "  torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "BR60qjCLcV67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first_training_loop(model, epochs, train_dataloader, val_dataloader, optimizer, criterion, device)\n",
        "#save_model(model, \"first_modele-1.pth\")"
      ],
      "metadata": {
        "id": "hMKARcZWSIol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1d) Validate your model\n",
        "\n",
        "- Show that the model is not overfitting\n",
        "- How does your model perform ?"
      ],
      "metadata": {
        "id": "cIAwvLE7RKmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm \n",
        "from sklearn import metrics\n",
        "\n",
        "def training_loop(model, epochs, train_dataloader, val_dataloader, optimizer, criterion, device):\n",
        "    total_train_losses = []\n",
        "    total_train_acc = []\n",
        "    total_val_losses = []\n",
        "    total_val_acc = []\n",
        "\n",
        "    for epoch in range(1,epochs+1):\n",
        "        print(f'epoch: {epoch}')\n",
        "        ##TRAINING##\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        trn_lbl = torch.Tensor([])\n",
        "        trn_preds = torch.Tensor([])\n",
        "        for i, batch, in enumerate(tqdm(train_dataloader)):\n",
        "            img_batch, lbl_batch = batch\n",
        "            trn_lbl=torch.cat((trn_lbl, lbl_batch))\n",
        "            img_batch, lbl_batch = img_batch.to(device), lbl_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(img_batch)\n",
        "            trn_preds=torch.cat((trn_preds, logits.argmax(1).cpu()))\n",
        "            loss=criterion(logits, lbl_batch)\n",
        "            wandb.log({\"train_loss\":loss.item()}) # log the training loss at each batch\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        train_acc=accuracy(trn_preds, trn_lbl)\n",
        "        train_loss_mean = np.mean(train_losses)\n",
        "\n",
        "        total_train_losses.append(train_loss_mean)\n",
        "        total_train_acc.append(train_acc)\n",
        "\n",
        "        ##VALIDATION##\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        val_lbl = torch.Tensor([])\n",
        "        val_preds = torch.Tensor([])\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for i, batch, in enumerate(tqdm(val_dataloader)):\n",
        "                img_batch, lbl_batch = batch\n",
        "                val_lbl=torch.cat((val_lbl, lbl_batch))\n",
        "                img_batch, lbl_batch = img_batch.to(device), lbl_batch.to(device)\n",
        "\n",
        "                logits=model(img_batch)\n",
        "                val_preds=torch.cat((val_preds, logits.argmax(1).cpu()))\n",
        "                loss=criterion(logits, lbl_batch)\n",
        "\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "        val_acc=accuracy(val_preds, val_lbl)\n",
        "        val_loss_mean = np.mean(val_losses)\n",
        "        wandb.log({\"train_acc\":train_acc, \"val_acc\":val_acc, \"val_loss\":val_loss_mean}) # log the train & val accuracy and the val loss at each epoch\n",
        "        \n",
        "        total_val_losses.append(val_loss_mean)\n",
        "        total_val_acc.append(val_acc)\n",
        "\n",
        "    cm = confusion_matrix(val_lbl, val_preds)\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "    disp.plot(xticks_rotation='vertical')\n",
        "    plt.show()\n",
        "    print(f'Accuracy: {accuracy(val_lbl, val_preds)}')\n",
        "    print(f'Precision: {precision(cm)}')\n",
        "    print(f'Recall: {recall(cm)}')\n",
        "    print(classification_report(val_lbl, val_preds, target_names=classes))\n",
        "\n",
        "    \n",
        "    return total_train_losses, total_train_acc, total_val_acc, total_val_losses\n",
        "\n",
        "    # save_graph(total_train_losses, total_val_losses, epochs, save_folder)\n",
        "\n"
      ],
      "metadata": {
        "id": "XOV-WsrWTzx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "model = ConvNet(3,3, nb_labels= 16)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 10\n",
        "\n",
        "# Training on GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "hyperparams = {\"Batch size\":batch_size,\n",
        "               \"Learning rate\":lr,\n",
        "               \"Epochs\":epochs}\n",
        "# *****END CODE\n",
        "\n",
        "# Init the WandB run with hyperparams\n",
        "wandb.init(config=hyperparams)\n",
        "\n",
        "total_train_losses, total_train_acc, total_val_acc, total_val_losses = training_loop(model, epochs, train_dataloader, val_dataloader, optimizer, criterion, device)\n",
        "\n",
        "save_model(model, \"model-e10-lr01.pth\")"
      ],
      "metadata": {
        "id": "vKxZyzPTT-Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the graphs \n",
        "\n",
        "def plot_results(total_train_losses, total_train_acc, total_val_acc, total_val_losses, epochs) :\n",
        "  # Accuracy\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(range(epochs),total_val_acc )\n",
        "  ax.plot(range(epochs),total_train_acc )\n",
        "  plt.title(\"Accuracy for each epoch for the training and the validation set\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  # Loss \n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(range(epochs),total_val_losses )\n",
        "  ax.plot(range(epochs),total_train_acc )\n",
        "  plt.title(\"Loss for each epoch for the training and the validation set\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "plot_results(total_train_losses, total_train_acc, total_val_acc, total_val_losses, epochs)"
      ],
      "metadata": {
        "id": "M6EwCxxA83gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does the model perform ?**\n",
        "\n",
        "From the graphs we can see that the training has gone well as threw time our each epoch our model is giving better and better performances on the training set. \n",
        "We can also see that the model seems to overfit as it has better performances on the train dataset but very poor ones on the validation..\n",
        "\n",
        "The confusion matrix seems to validate our observations as the F1-score is only XX. The accuracy isn't also very good neither are the other Precision and Recall. \n",
        "\n",
        "One solution we could have would be to optimize the hyperparameters."
      ],
      "metadata": {
        "id": "Ol0a2bYt7Ean"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1e) Try to optimize hyperparameters, does it improve the performance of your model ?\n",
        "Anwser with a graph and comment on the result."
      ],
      "metadata": {
        "id": "J7B9gOlwbYny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a model from scratch for all these different learning rates\n",
        "# and store the final validation accuracy in a array\n",
        "rates = [10**2, 1, 10**(-2), 10**(-4), 10**(-6)]\n",
        "\n",
        "\n",
        "for lr in rates : \n",
        "  model = ConvNet(3,3, nb_labels= 16)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  epochs = 10\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "  # Training on GPU\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "\n",
        "  hyperparams = {\"Batch size\":batch_size,\n",
        "                \"Learning rate\":lr,\n",
        "                \"Epochs\":epochs}\n",
        "\n",
        "  # Init the WandB run with hyperparams\n",
        "  wandb.init(config=hyperparams)\n",
        "  \n",
        "  total_train_losses, total_train_acc, total_val_acc, total_val_losses = training_loop(model, epochs, train_dataloader, val_dataloader, optimizer, criterion, device)\n",
        "  save_model(model, f\"model-e10-lr{lr}.pth\")\n",
        "  plot_results(total_train_losses, total_train_acc, total_val_acc, total_val_losses, epochs)"
      ],
      "metadata": {
        "id": "9bonlE17g1n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k5ePcF28dUMv",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1f) Get an intermediate layer from your convolutional neural network and visualize what patterns the network has learned\n",
        "*   Complete the following code that visualizes the patterns of the network\n",
        "*   Write a small description commenting on the visualized maps. What do you observe in the different visualizations of the feature maps?"
      ],
      "metadata": {
        "id": "1Kp8nRiGRKmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The intermediate layer you should visualize:\n",
        "print('My intermediate layer to visualize is: %s'%(my_architecture_dict['visualize']))"
      ],
      "metadata": {
        "id": "jSSGZEoFVm-k",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from skimage import io\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "##function for printing the loss during optimization\n",
        "def write_flush(text, stream=sys.stdout):\n",
        "    stream.write(text)\n",
        "    stream.flush()\n",
        "    return\n",
        "\n",
        "## Number of feature maps in the intermediate layer that you have chosen. \n",
        "# *****START CODE\n",
        "n_conv =   # e.g 64\n",
        "# *****END CODE\n",
        "\n",
        "## Size of visualised filter.\n",
        "img_size = 32\n",
        "\n",
        "##load your optimal model\n",
        "# *****START CODE\n",
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load('drive/..../model.pt')) \n",
        "# *****END CODE\n",
        "\n",
        "## Create a submodel, until the intermediate layer of your choice.\n",
        "## Hint: Use model.#name# to create the succession of layers, where #name#\n",
        "## stands for the layer names that you defined in the initialization function \n",
        "## of your model.\n",
        "# *****START CODE\n",
        "submodel = nn.Sequential(\n",
        "\n",
        "    \n",
        ")\n",
        "# *****END CODE\n",
        "\n",
        "## Put submodel in eval mode.\n",
        "submodel.eval()\n",
        "\n",
        "## Tensor to visualised filters. \n",
        "img_stack = torch.zeros((n_conv, 3, img_size, img_size))\n",
        "\n",
        "## Number of epochs to run for every filter. \n",
        "# *****START CODE\n",
        "n_epochs_per_filt =   #e.g 30\n",
        "# *****END CODE\n",
        "\n",
        "## Visualise every convolution. \n",
        "for c in range(n_conv):\n",
        "    ## Initialise with random image. \n",
        "    img = torch.rand(1, 3, img_size, img_size).float()\n",
        "\n",
        "    ## Turn on gradient calculation on the image\n",
        "    # *****START CODE\n",
        "\n",
        "    # *****END CODE\n",
        "\n",
        "    ## Define optimizer.\n",
        "    # *****START CODE\n",
        "    \n",
        "    # *****END CODE\n",
        "    \n",
        "    for f in range(n_epochs_per_filt):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ## Feedforward propagation\n",
        "        ## Hint: In order to find the loss, compupte the negative of the activation of the hidden layer. \n",
        "        ## The objective is to produce an input image which maximizes the activation \n",
        "        ## of neurons in a particular hidden layer. \n",
        "        # *****START CODE\n",
        "        \n",
        "        \n",
        "        \n",
        "        # *****END CODE\n",
        "        write_flush('\\rFilter %d. Epoch %d. Loss = %.4f'%(c, f+1, loss.item()))\n",
        "\n",
        "    write_flush('\\n')\n",
        "    img_stack[c, :, :, :] = img[0].detach()\n",
        "\n",
        "## Make grid out of visualized filters. \n",
        "##Here you may have to adjust the properties of vutils.make_grid, depending on your needs. \n",
        "##For example, you may need to change the number of rows.\n",
        "G = vutils.make_grid(img_stack, nrow=8, normalize=True, padding=1).permute(1,2,0).numpy()\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(G)\n",
        "plt.axis('equal')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xk4FadJSRKmG",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1g) Use GradCAM algorithm to visualize the saliency maps of your trained model at the same intermediate layer\n",
        "*   Install pytorch grad cam package if needed (https://github.com/jacobgil/pytorch-grad-cam)\n",
        "*   Complete the following code that visualizes GradCAM heatmaps on an input image from your model\n",
        "*   Try on several input images / classes. \n",
        "*   Write a small description commenting on the visualized heatmaps. "
      ],
      "metadata": {
        "id": "4dfeLUNQVm-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pytorch grad cam package\n",
        "'''UNCOMMENT IF NEEDED (using google colab for example)\n",
        "! pip install grad-cam\n",
        "'''\n"
      ],
      "metadata": {
        "id": "jkXGgb11Vm-l",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "use_cuda = True\n",
        "\n",
        "# *****START CODE\n",
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load('drive/..../model.pt'))\n",
        "\n",
        "# Get your intermediate layer\n",
        "target_layers = [model. ...]\n",
        "\n",
        "rgb_img = \n",
        "input_tensor = # Create an input tensor from your image for your model..\n",
        "# Note: input_tensor can be a batch tensor with several images!\n",
        "target_category = \n",
        "# *****END CODE\n",
        "\n",
        "# Construct the CAM object once, and then re-use it on many images:\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
        "\n",
        "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)\n",
        "\n",
        "# In this example grayscale_cam has only one image in the batch:\n",
        "grayscale_cam = grayscale_cam[0, :]\n",
        "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "# Plot figure\n",
        "plt.figure()\n",
        "plt.imshow(visualization)"
      ],
      "metadata": {
        "id": "FU7OPn3cVm-l",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2 - Train on geometrical shapes"
      ],
      "metadata": {
        "id": "o3QK7dhJRKmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function 'generate_a_triangle' produces images depicting random triangles along with the (x,y) coordinates of the vertices. Create a convolutional neural network that receives as input the triangle image and predicts the corresponding (x,y) coordinates of the triangle's vertices. \n",
        "*  Read and understand the following code"
      ],
      "metadata": {
        "id": "-yudhcXrRKmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "# On some implementations of matplotlib, you may need to change this value\n",
        "IMAGE_SIZE = 72\n",
        "\n",
        "def generate_a_drawing(figsize, U, V):\n",
        "    fig = plt.figure(figsize=(figsize,figsize))\n",
        "    ax = plt.subplot(111)\n",
        "    plt.axis('Off')\n",
        "    ax.set_xlim(0,figsize)\n",
        "    ax.set_ylim(0,figsize)\n",
        "    ax.fill(U, V, \"k\")\n",
        "    fig.canvas.draw()\n",
        "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
        "    imdata = imdata + np.random.random(imdata.size)\n",
        "    plt.close(fig)\n",
        "    return imdata\n",
        "\n",
        "def generate_a_triangle():\n",
        "    figsize = 1.0\n",
        "    U = np.random.random(3)\n",
        "    V = np.random.random(3)\n",
        "    imdata = generate_a_drawing(figsize, U, V)\n",
        "    return [imdata, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
        "\n",
        "[im, v] = generate_a_triangle()\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
        "\n",
        "def generate_dataset_regression(nb_samples):\n",
        "    # Getting im_size:\n",
        "    im_size = generate_a_triangle()[0].shape[0]\n",
        "    X = np.zeros([nb_samples,im_size])\n",
        "    Y = np.zeros([nb_samples, 6])\n",
        "    print('Creating data:')\n",
        "    for i in range(nb_samples):\n",
        "        if i % 10 == 0:\n",
        "            print(i)\n",
        "        [X[i], Y[i]] = generate_a_triangle()\n",
        "    X = X / 255\n",
        "    return [X, Y]\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_prediction(x, y):\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    I = x.reshape((IMAGE_SIZE,IMAGE_SIZE))\n",
        "    ax.imshow(I, extent=[-0.15,1.15,-0.15,1.15],cmap='gray')\n",
        "    ax.set_xlim([0,1])\n",
        "    ax.set_ylim([0,1])\n",
        "\n",
        "    xy = y.reshape(3,2)\n",
        "    tri = patches.Polygon(xy, closed=True, fill = False, edgecolor = 'r', linewidth = 5, alpha = 0.5)\n",
        "    ax.add_patch(tri)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def generate_test_set_regression():\n",
        "    np.random.seed(42)\n",
        "    [X_test, Y_test] = generate_dataset_regression(300)\n",
        "    return [X_test, Y_test]"
      ],
      "metadata": {
        "id": "aptobJOZbRZd",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2a) Use function 'generate_dataset_regression' to create the dataset. Split the dataset to training and validation parts."
      ],
      "metadata": {
        "id": "clB8r3jMRKmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##generate dataset\n",
        "# *****START CODE\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "6Y7mW83fRKmJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##split the dataset to training and validation parts\n",
        "# *****START CODE\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "xIwVanB4RKmK",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.295512Z",
          "iopub.status.idle": "2022-12-14T14:53:20.296180Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.295882Z",
          "shell.execute_reply": "2022-12-14T14:53:20.295908Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2b) Use function 'generate_test_set' to create the testing dataset."
      ],
      "metadata": {
        "id": "NEoZyhgZRKmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##generate test dataset\n",
        "# *****START CODE\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "PE6e3nszRKmK",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.297733Z",
          "iopub.status.idle": "2022-12-14T14:53:20.298463Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.298175Z",
          "shell.execute_reply": "2022-12-14T14:53:20.298200Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2c) Create your own convolutional neural network.\n",
        "* Begin with the previous exercise model architecture\n",
        "* Optimize the architecture to perform well on predicting the different coordinates"
      ],
      "metadata": {
        "id": "tcsDj8eQRKmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# *****START CODE\n",
        "class ConvNetR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetR, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "hQYXQV5LRKmL",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.301455Z",
          "iopub.status.idle": "2022-12-14T14:53:20.302789Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.302489Z",
          "shell.execute_reply": "2022-12-14T14:53:20.302518Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2d) Define learning rate, model, optimizer, criterion and number of epochs."
      ],
      "metadata": {
        "id": "U6PxmyfqRKmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "lr = \n",
        "model = \n",
        "optimizer = \n",
        "criterion = \n",
        "epochs = \n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "vS9LIDmlRKmM",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.304202Z",
          "iopub.status.idle": "2022-12-14T14:53:20.304766Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.304463Z",
          "shell.execute_reply": "2022-12-14T14:53:20.304497Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2e) What criterion did you choose and why?\n",
        "* Write a small description for the loss function that you want to use for this specific problem.\n",
        "* What was your intuition for using this loss?"
      ],
      "metadata": {
        "id": "JNtKYgzTRKmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2f) Train your model and validate it at the end of each epoch.\n",
        "* Similarly to the previous question train and validate your network for each epoch\n",
        "* Write a small description on how you decide which is the optimal epoch\n",
        "* Use this epoch and evaluate your model on the test set\n",
        "* Visualise some predictions using the function 'visualize_prediction'\n",
        "* What do you observe?"
      ],
      "metadata": {
        "id": "HmjN0W-KRKmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "\n",
        "\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "VZfRftoFRKmN",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.306222Z",
          "iopub.status.idle": "2022-12-14T14:53:20.306904Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.306580Z",
          "shell.execute_reply": "2022-12-14T14:53:20.306622Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2g) Think and implement a preprocessing step that can boost the accuracy of your network"
      ],
      "metadata": {
        "id": "zTCMv88pRKmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "\n",
        "\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "jTqLTm8LRKmN",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.308652Z",
          "iopub.status.idle": "2022-12-14T14:53:20.309416Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.309202Z",
          "shell.execute_reply": "2022-12-14T14:53:20.309224Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3\n",
        "Answer these generic questions:"
      ],
      "metadata": {
        "id": "qmogb4BZqanY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3a) What is a metric? What is a loss? What is the difference between both?"
      ],
      "metadata": {
        "id": "UI7zK3GOqiPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "Fse981-xqsaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b) Why deep learning models are difficult to understand even on a particular prediction?"
      ],
      "metadata": {
        "id": "LEPKyXQzqu0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "zkE-FQ3aq_Pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3c) What is \"out of domain data\"?"
      ],
      "metadata": {
        "id": "nB17ceedrBvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "GSxTeaBbrN39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3d) Name five tasks where Deep Learning models are the state-of-the-art:\n",
        "For example: Folding proteins in Biology"
      ],
      "metadata": {
        "id": "gW4zn1h6rO8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "26X2qPH6ruN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3e)What is an “activation function” and what is it used for in Deep Learning models?"
      ],
      "metadata": {
        "id": "z9aeE0ikrvUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "pIgnFkHGtA-k"
      }
    }
  ]
}