{
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o3QK7dhJRKmH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "vscode": {
      "interpreter": {
        "hash": "d8a1dba90a7a3c73ffa205c3fa0146003aed819f1f43d631078b51d929ccab9c"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrienloizeau/cifar-pytorch-model-/blob/main/fdl_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FDL- DSBA Assignment 2022-2023\n",
        "\n",
        "### Please fill the blanks in the code and answer to the questions that are asked in the Jupyter Notebook (\"Markdown\" cell). \n",
        "\n",
        "### Instructions: Rename the jupyter adding your name at the end of the title FDL_Assignment-<YOUR NAME\\>.ipynb\n",
        "\n",
        "### Upload your solution on Edunao before the 19/12/2022 (December the 12th), and set the file name to FDL_Assignment-<YOUR NAME\\>\n",
        "\n",
        "For any questions, please contact Arthur Ledaguenel at arthur.ledaguenel@centralesupelec.fr and put \\[FDL\\] in the object of the mail"
      ],
      "metadata": {
        "id": "HzT-fZzFRKly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 -  TRAIN ON CIFAR DATASET\n",
        "In this exercise you are asked to train a Convolutional Neural Network (CNN) on the CIFAR10 dataset and visualize its feature maps."
      ],
      "metadata": {
        "id": "zPUOV6dFRKl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1a) Download the CIFAR10 dataset using the already provided PyTorch dataloaders. \n",
        "*   Read and understand the following code\n",
        "*   Feel free to add additional transformations of data. Explain if so. "
      ],
      "metadata": {
        "id": "lCX0xLejRKl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10"
      ],
      "metadata": {
        "id": "31bJgkWSUt8u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Download the CIFAR10 dataset using the PyTorch dataloaders\n",
        "import json \n",
        "from pprint import pprint\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# *****START CODE \n",
        "## Data\n",
        "##Here you are free to add further transform functions if you wish\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size= batch_size , shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "val_dataloader = torch.utils.data.DataLoader(testset, batch_size= batch_size, shuffle=False)\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "5KyVunArRKl-",
        "outputId": "9659ad08-8425-4df6-90f9-e36f78b4395e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:29.144140Z",
          "iopub.execute_input": "2022-12-14T15:04:29.144487Z",
          "iopub.status.idle": "2022-12-14T15:04:30.820640Z",
          "shell.execute_reply.started": "2022-12-14T15:04:29.144458Z",
          "shell.execute_reply": "2022-12-14T15:04:30.819654Z"
        },
        "trusted": true
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b) Create your convolutional neural network.\n",
        "*   Go to https://dljudge.io/generate + /<YOUR NAME\\> or use curl below\n",
        "*   Save the page as json \n",
        "*   Build your CNN architecture based on those modules and hyperparameters\n",
        "*   Use the right value for 'COMPUTE' \n",
        "*   See the example below"
      ],
      "metadata": {
        "id": "3S-ITJo9RKmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://dljudge.io/generate/adrienloizeau -o network1.json"
      ],
      "metadata": {
        "id": "gnmWWieDVm-g",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:30.822377Z",
          "iopub.execute_input": "2022-12-14T15:04:30.823081Z",
          "iopub.status.idle": "2022-12-14T15:04:31.894808Z",
          "shell.execute_reply.started": "2022-12-14T15:04:30.823040Z",
          "shell.execute_reply": "2022-12-14T15:04:31.893610Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_network(model, input_dict):\n",
        "    \"\"\"\n",
        "    Validate if your network definition is same as provided architecture\n",
        "    \"\"\"\n",
        "    output = {}\n",
        "    i = 1\n",
        "    for layer in model.children():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'Conv2d',\n",
        "                                                  'kernel_size': layer.kernel_size[0],\n",
        "                                                   'input': layer.in_channels,\n",
        "                                                   'output': layer.out_channels,\n",
        "                                                   'padding': layer.padding[0]}\n",
        "\n",
        "        if isinstance(layer, nn.ReLU):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'ReLU'}\n",
        "\n",
        "        if isinstance(layer, nn.MaxPool2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'MaxPool2d',\n",
        "                                                  'kernel_size': layer.kernel_size,\n",
        "                                                  'stride': layer.stride}\n",
        "\n",
        "        if isinstance(layer, nn.AdaptiveAvgPool2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'AdaptiveAvgPool2d',\n",
        "                                                  'output': layer.output_size}\n",
        "\n",
        "        if isinstance(layer, nn.BatchNorm2d):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'BatchNorm2d',\n",
        "                                                  'input': layer.num_features}\n",
        "\n",
        "        if isinstance(layer, nn.Dropout):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'Dropout',\n",
        "                                                  'p': layer.p}\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            output[f'Layer_{str(i).zfill(3)}'] = {'type': 'Linear',\n",
        "                                                  'input': layer.in_features,\n",
        "                                                  'output': layer.out_features}\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    \n",
        "    correct = True\n",
        "    for l in output.keys():\n",
        "        if l in input_dict:\n",
        "            inp_kvs = input_dict[l]\n",
        "            out_kvs = output[l]\n",
        "            for k in out_kvs:\n",
        "                if inp_kvs[k] != 'COMPUTE':\n",
        "                    if out_kvs[k] != inp_kvs[k]:\n",
        "                        print(out_kvs[k])\n",
        "                        print (f'Error in {l}, {k}!')\n",
        "                        correct = False\n",
        "\n",
        "    if correct:\n",
        "        print ('OK!')"
      ],
      "metadata": {
        "id": "fut0mqaSVm-g",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:31.897452Z",
          "iopub.execute_input": "2022-12-14T15:04:31.897880Z",
          "iopub.status.idle": "2022-12-14T15:04:31.910698Z",
          "shell.execute_reply.started": "2022-12-14T15:04:31.897825Z",
          "shell.execute_reply": "2022-12-14T15:04:31.909659Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE \n",
        "# Import your individual architecture dictionnary here\n",
        "fin = open('CNN.json', 'r')\n",
        "my_architecture_dict = json.load(fin)\n",
        "fin.close()\n",
        "\n",
        "pprint(my_architecture_dict)\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "hiihuvTRVm-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6355748-1e40-44b8-9c36-4416a1a8c7b1",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:32.505968Z",
          "iopub.execute_input": "2022-12-14T15:04:32.506314Z",
          "iopub.status.idle": "2022-12-14T15:04:32.516331Z",
          "shell.execute_reply.started": "2022-12-14T15:04:32.506284Z",
          "shell.execute_reply": "2022-12-14T15:04:32.515318Z"
        },
        "trusted": true
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Layer_001': {'input': 3,\n",
            "               'kernel_size': 3,\n",
            "               'output': 56,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_002': {'type': 'ReLU'},\n",
            " 'Layer_003': {'kernel_size': 2, 'stride': 2, 'type': 'MaxPool2d'},\n",
            " 'Layer_004': {'input': 56,\n",
            "               'kernel_size': 3,\n",
            "               'output': 135,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_005': {'type': 'ReLU'},\n",
            " 'Layer_006': {'kernel_size': 2, 'stride': 2, 'type': 'MaxPool2d'},\n",
            " 'Layer_007': {'input': 135,\n",
            "               'kernel_size': 3,\n",
            "               'output': 246,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_008': {'type': 'ReLU'},\n",
            " 'Layer_009': {'input': 246,\n",
            "               'kernel_size': 3,\n",
            "               'output': 246,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_010': {'type': 'ReLU'},\n",
            " 'Layer_011': {'kernel_size': 2, 'stride': 2, 'type': 'MaxPool2d'},\n",
            " 'Layer_012': {'input': 246,\n",
            "               'kernel_size': 3,\n",
            "               'output': 520,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_013': {'type': 'ReLU'},\n",
            " 'Layer_014': {'input': 520,\n",
            "               'kernel_size': 3,\n",
            "               'output': 520,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_015': {'type': 'ReLU'},\n",
            " 'Layer_016': {'kernel_size': 2, 'stride': 2, 'type': 'MaxPool2d'},\n",
            " 'Layer_017': {'input': 520,\n",
            "               'kernel_size': 3,\n",
            "               'output': 520,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_018': {'type': 'ReLU'},\n",
            " 'Layer_019': {'input': 520,\n",
            "               'kernel_size': 3,\n",
            "               'output': 520,\n",
            "               'padding': 1,\n",
            "               'type': 'Conv2d'},\n",
            " 'Layer_020': {'type': 'ReLU'},\n",
            " 'Layer_021': {'kernel_size': 2, 'stride': 2, 'type': 'MaxPool2d'},\n",
            " 'Layer_022': {'output': 'COMPUTE', 'type': 'AdaptiveAvgPool2d'},\n",
            " 'Layer_023': {'p': 0.5112472379693787, 'type': 'Dropout'},\n",
            " 'Layer_024': {'input': 'COMPUTE', 'output': 2142, 'type': 'Linear'},\n",
            " 'Layer_025': {'type': 'ReLU'},\n",
            " 'Layer_026': {'p': 0.5112472379693787, 'type': 'Dropout'},\n",
            " 'Layer_027': {'input': 2142, 'output': 3067, 'type': 'Linear'},\n",
            " 'Layer_028': {'type': 'ReLU'},\n",
            " 'Layer_029': {'p': 0.5112472379693787, 'type': 'Dropout'},\n",
            " 'Layer_030': {'input': 3067, 'output': 3922, 'type': 'Linear'},\n",
            " 'Layer_031': {'type': 'ReLU'},\n",
            " 'Layer_032': {'input': 3922, 'output': 'COMPUTE', 'type': 'Linear'},\n",
            " 'StudentName': 'adrienloizeau',\n",
            " 'UUID': 'cefc8f3e5faa458c8add44008a6a7390'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the model"
      ],
      "metadata": {
        "id": "H0GdydoAakXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# *****START CODE\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, inplanes :int, planes : int, stride = 1, downsample = None, \n",
        "                 groups = 1, base_width = 64, dilation = 1, norm_layer = None, final_images = 16):\n",
        "        super(ConvNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        # ? \n",
        "        # width = int(planes * (base_width / 64.0)) * groups\n",
        "\n",
        "        width = int(planes * (base_width / 64.0)) * groups\n",
        "\n",
        "        self.conv1  = nn.Conv2d(width,56,3,padding  = 1)\n",
        "        self.batch1 =nn.BatchNorm2d(56)\n",
        "\n",
        "        self.relu1  = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv2  = nn.Conv2d(56,135,3,padding  = 1)\n",
        "        self.batch2 =nn.BatchNorm2d(135)\n",
        "\n",
        "        self.relu2  = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.conv3  = nn.Conv2d(135,246,3,padding  = 1)\n",
        "        self.batch3 =nn.BatchNorm2d(246)\n",
        "        \n",
        "        self.relu3  = nn.ReLU()\n",
        "        self.conv4  = nn.Conv2d(246,246,3,padding  = 1)\n",
        "        \n",
        "        self.batch4 =nn.BatchNorm2d(246)\n",
        "        self.relu4  = nn.ReLU()\n",
        "        #10 \n",
        "        \n",
        "        self.maxpool3 = nn.MaxPool2d(2,2)\n",
        "        self.conv5  = nn.Conv2d(246,520,3,padding  = 1)\n",
        "        \n",
        "        self.batch5 =nn.BatchNorm2d(520)\n",
        "        self.relu5  = nn.ReLU()\n",
        "        \n",
        "        self.conv6  = nn.Conv2d(520,520,3,padding  = 1)\n",
        "        self.batch6 =nn.BatchNorm2d(520)\n",
        "\n",
        "        self.relu6  = nn.ReLU()\n",
        "        self.maxpool4 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        self.conv7  = nn.Conv2d(520,520,3,padding  = 1)\n",
        "        self.batch7 = nn.BatchNorm2d(520)\n",
        "        \n",
        "        self.relu7  = nn.ReLU()\n",
        "        self.conv8  = nn.Conv2d(520,520,3,padding  = 1)\n",
        "        \n",
        "        self.batch8 = nn.BatchNorm2d(520)\n",
        "        self.relu8  = nn.ReLU()\n",
        "        \n",
        "        self.maxpool5 = nn.MaxPool2d(2,2)\n",
        "        # Compute here set to 520 to fit the previous modules. \n",
        "        # AdaptiveAvgPool2d makes an average pooling\n",
        "        self.adapt1 = nn.AdaptiveAvgPool2d(1)\n",
        "        \n",
        "        # Does not modify the size \n",
        "        self.dropout1 = nn.Dropout(p=0.5112472379693787)\n",
        "        # We still are only with 520\n",
        "        # self.flaten1 = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(520, 2142)\n",
        "        \n",
        "        self.relu9 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(p=0.5112472379693787)\n",
        "        \n",
        "        self.linear2 = nn.Linear(2142,3067)\n",
        "        self.relu10 = nn.ReLU()\n",
        "\n",
        "        self.dropout3 = nn.Dropout(p=0.5112472379693787)\n",
        "        self.linear3 = nn.Linear(3067,3922)\n",
        "        \n",
        "        self.relu11 = nn.ReLU()\n",
        "        \n",
        "        self.linear4 = nn.Linear(3922,batch_size * planes)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        x = self.batch2(x)\n",
        "        x = self.relu2(x)\n",
        "        \n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x = self.batch3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batch4(x)\n",
        "        \n",
        "        x = self.relu4(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batch5(x)\n",
        "        \n",
        "        x = self.relu5(x)\n",
        "        x = self.conv6(x)\n",
        "        \n",
        "        x = self.batch6(x)\n",
        "        x = self.relu6(x)\n",
        "        \n",
        "        x = self.maxpool4(x)\n",
        "        x = self.conv7(x)\n",
        "\n",
        "        x = self.batch7(x)\n",
        "        x = self.relu7(x)\n",
        "        \n",
        "        x = self.conv8(x)\n",
        "        x = self.batch8(x)\n",
        "\n",
        "        \n",
        "        x = self.relu8(x)\n",
        "        x = self.maxpool5(x)\n",
        "        \n",
        "        x = self.adapt1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.linear1(x)\n",
        "        x = self.relu9(x)\n",
        "\n",
        "        x = self.dropout2(x)\n",
        "        x = self.linear2(x)\n",
        "        \n",
        "        x = self.relu10(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.linear3(x)\n",
        "        x = self.relu11(x)\n",
        "\n",
        "        x = self.linear4(x)\n",
        "        return x\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "9hb1skoXRKmA",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:33.105546Z",
          "iopub.execute_input": "2022-12-14T15:04:33.106906Z",
          "iopub.status.idle": "2022-12-14T15:04:33.128005Z",
          "shell.execute_reply.started": "2022-12-14T15:04:33.106860Z",
          "shell.execute_reply": "2022-12-14T15:04:33.126969Z"
        },
        "trusted": true
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1c) Create the training scheme\n",
        "*    Initialize the model\n",
        "*    Validate the model\n",
        "*    Specify the training hyperparameters like type of optimizer, criterion and learning rate\n",
        "*    Specify number of epochs\n",
        "*    Connect the model and any further informations to WandB\n",
        "\n",
        "Then train the model, doing one evaluation pass per epoch (make sure to log any interesting metric to WandB during training)."
      ],
      "metadata": {
        "id": "1oCW4FGORKmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing wandb"
      ],
      "metadata": {
        "id": "IYf6_blAW26z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet\n",
        "\n",
        "# Import the library\n",
        "import wandb\n",
        "# Then connect to your W&B account\n",
        "def wandb_connect():\n",
        "    wandb_api_key_label = \"77e0a94a0fa993f825495a3021ebfa5477225ce9\"\n",
        "    wandb_api_key = \"\" # here use your API key from WandB interface\n",
        "\n",
        "    wandb_conx = wandb.login(key = wandb_api_key)\n",
        "    print(f\"Connected to Wandb online interface : {wandb_conx}\")\n",
        "\n",
        "wandb_connect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsIk7NZCxeVO",
        "outputId": "a94efb01-5851-4e5d-84e5-da833cb97b0a",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:34.726659Z",
          "iopub.execute_input": "2022-12-14T15:04:34.727535Z",
          "iopub.status.idle": "2022-12-14T15:04:44.377813Z",
          "shell.execute_reply.started": "2022-12-14T15:04:34.727496Z",
          "shell.execute_reply": "2022-12-14T15:04:44.376661Z"
        },
        "trusted": true
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to Wandb online interface : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchnet\n",
        "import torchnet as tnt # why not use torch metrics ?\n",
        "\n",
        "# define confusion matrix using tnt package\n",
        "confusion_matrix = tnt.meter.ConfusionMeter(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssNEw2adXbWV",
        "outputId": "e4039d5b-c16d-49ce-db59-a2a7e0a8ba76",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:44.380122Z",
          "iopub.execute_input": "2022-12-14T15:04:44.380907Z",
          "iopub.status.idle": "2022-12-14T15:04:53.699735Z",
          "shell.execute_reply.started": "2022-12-14T15:04:44.380864Z",
          "shell.execute_reply": "2022-12-14T15:04:53.698553Z"
        },
        "trusted": true
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchnet in /usr/local/lib/python3.8/dist-packages (0.0.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchnet) (1.13.0+cu116)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchnet) (1.15.0)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.8/dist-packages (from torchnet) (0.2.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchnet) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (1.7.3)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (1.4.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (2.8.8)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (1.32)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.8/dist-packages (from visdom->torchnet) (6.0.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.8/dist-packages (from jsonpatch->visdom->torchnet) (2.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->visdom->torchnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->visdom->torchnet) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->visdom->torchnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->visdom->torchnet) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring data before training"
      ],
      "metadata": {
        "id": "-j4WwxfJLPX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "batch_size= 2\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "# get some random training images\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:53.701543Z",
          "iopub.execute_input": "2022-12-14T15:04:53.701973Z",
          "iopub.status.idle": "2022-12-14T15:04:53.953799Z",
          "shell.execute_reply.started": "2022-12-14T15:04:53.701931Z",
          "shell.execute_reply": "2022-12-14T15:04:53.952825Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "H8wIQB1KLPX-",
        "outputId": "7fde130e-5a22-4f14-951f-58740cad6b21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car   bird \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Back to code : defining the learning rate, optimizer and criterion"
      ],
      "metadata": {
        "id": "8xreesy0LPX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "import torch\n",
        "\n",
        "lr = 0.01\n",
        "model = ConvNet(3,3, batch_size= 10)\n",
        "#validate_network(model, my_architecture_dict)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 10\n",
        "confusion_matrix.reset()\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "emDRadjhRKmD",
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:53.956301Z",
          "iopub.execute_input": "2022-12-14T15:04:53.956971Z",
          "iopub.status.idle": "2022-12-14T15:04:54.235721Z",
          "shell.execute_reply.started": "2022-12-14T15:04:53.956934Z",
          "shell.execute_reply": "2022-12-14T15:04:54.234644Z"
        },
        "trusted": true
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the hyperparams dict with the infos of your run\n",
        "# *****START CODE\n",
        "hyperparams = {\"Batch size\":32,\n",
        "               \"Learning rate\":lr,\n",
        "               \"Epochs\":epochs}\n",
        "# *****END CODE\n",
        "\n",
        "# Init the WandB run with hyperparams\n",
        "wandb.init(config=hyperparams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "bNx4JHRJUl3j",
        "outputId": "5d9d61f2-195a-4d7c-cf5e-94f86d2239b6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221214_154915-1usz1md9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/adrienloizeau/uncategorized/runs/1usz1md9\" target=\"_blank\">cosmic-voice-5</a></strong> to <a href=\"https://wandb.ai/adrienloizeau/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/adrienloizeau/uncategorized/runs/1usz1md9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f501188ce20>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First training loop"
      ],
      "metadata": {
        "id": "vZfe1nY7LPYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:54.237373Z",
          "iopub.execute_input": "2022-12-14T15:04:54.237780Z",
          "iopub.status.idle": "2022-12-14T15:04:54.244433Z",
          "shell.execute_reply.started": "2022-12-14T15:04:54.237743Z",
          "shell.execute_reply": "2022-12-14T15:04:54.243366Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uux0Yf09LPYB",
        "outputId": "53d0b210-c151-442c-a60d-a17b3f2c381b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(tqdm(train_dataloader, 0)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-14T15:04:54.245731Z",
          "iopub.execute_input": "2022-12-14T15:04:54.246654Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "gqzUm6MILPYC",
        "outputId": "a76350aa-a80f-4a5f-d3c5-51539016a9ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 38/5000 [00:14<31:19,  2.64it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-d0d423db9489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "PATH = 'model-10.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8fh8_wBgLPYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)\n",
        "print(criterion(outputs, labels))"
      ],
      "metadata": {
        "id": "4kW13_XuYTnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c997e7e-af18-4d94-c50d-fc5b781c8c35"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1426,  0.9196, -0.1024,  0.5389,  0.2232,  0.0480,  0.0388,  0.2114,\n",
            "         -0.0804,  0.3333,  0.0158, -0.0602,  0.2669, -0.0930, -0.1573, -0.1403,\n",
            "          0.1423, -0.0308, -0.2987, -0.0271,  0.0049, -0.1397, -0.1588,  0.1229,\n",
            "          0.2475, -0.1603, -0.0563, -0.2315, -0.0585, -0.2889],\n",
            "        [ 0.0110,  0.9931, -0.3682,  0.6564,  0.0942,  0.1168,  0.0602,  0.1620,\n",
            "         -0.1767,  0.3298, -0.0150,  0.0742, -0.1464, -0.1788,  0.1259, -0.0043,\n",
            "         -0.0740, -0.1604, -0.1224, -0.3596, -0.0384, -0.2524, -0.1658,  0.0110,\n",
            "          0.0055, -0.2441, -0.1090, -0.0881, -0.1346, -0.1471],\n",
            "        [-0.1591,  0.9636, -0.4409,  0.6767,  0.1636,  0.0215,  0.1832,  0.4554,\n",
            "         -0.1759,  0.5849,  0.1015, -0.2128, -0.0584, -0.1195, -0.1582,  0.1315,\n",
            "         -0.2566, -0.1444, -0.3929, -0.2485, -0.0600, -0.2951, -0.2408, -0.1551,\n",
            "          0.0102, -0.1544, -0.1824, -0.1129, -0.1445, -0.2294],\n",
            "        [-0.1722,  0.7117, -0.2799,  0.3305,  0.0445, -0.0430,  0.1599,  0.5368,\n",
            "         -0.1322,  0.3294, -0.0139, -0.1138,  0.0698,  0.0695, -0.1040,  0.0357,\n",
            "         -0.2153, -0.2136,  0.0673, -0.0738,  0.1787, -0.3119, -0.2031,  0.0050,\n",
            "          0.2884, -0.3285, -0.1694, -0.0274, -0.3029, -0.0969],\n",
            "        [-0.1652,  1.0912, -0.1939,  0.4158,  0.4010, -0.0447, -0.1465,  0.2501,\n",
            "         -0.5569,  0.2900,  0.0942, -0.0713, -0.1266, -0.1418, -0.0625, -0.2057,\n",
            "         -0.1094, -0.2109, -0.2057, -0.0665, -0.0323, -0.1877, -0.3998, -0.0255,\n",
            "          0.0130, -0.1177, -0.2016, -0.2704, -0.0972, -0.1166],\n",
            "        [-0.1867,  0.9003, -0.2741,  0.6343,  0.1720, -0.1515,  0.1855,  0.3540,\n",
            "         -0.0461,  0.4493, -0.0042,  0.0279, -0.2102,  0.1239, -0.1085, -0.1268,\n",
            "         -0.0625, -0.1916, -0.0205, -0.2974,  0.0220, -0.1191, -0.1007, -0.2760,\n",
            "         -0.1497, -0.0494, -0.2711, -0.0148, -0.0829,  0.1063],\n",
            "        [-0.1718,  1.1756, -0.1382,  0.6462,  0.0484, -0.0574,  0.1533,  0.3171,\n",
            "         -0.1570,  0.1190, -0.0055, -0.0161, -0.1948, -0.2257, -0.0094, -0.1213,\n",
            "         -0.2057, -0.0043, -0.1620, -0.1242,  0.1423, -0.0788, -0.1900,  0.0244,\n",
            "          0.0182, -0.2323, -0.1835, -0.2282, -0.2118, -0.2838],\n",
            "        [-0.0188,  0.6611, -0.2178,  0.3920,  0.0889,  0.0255, -0.0540,  0.3811,\n",
            "         -0.1198,  0.2744,  0.0151, -0.0408, -0.0360,  0.0889,  0.0295, -0.1539,\n",
            "         -0.1494, -0.1022, -0.2004, -0.0600,  0.0382, -0.0530, -0.2806, -0.1131,\n",
            "          0.0014, -0.0048, -0.1155,  0.0325,  0.0022, -0.1388],\n",
            "        [ 0.0422,  1.2918, -0.4416,  0.5200, -0.0920,  0.2443,  0.5422,  0.5007,\n",
            "         -0.0339,  0.1776,  0.2208,  0.1201, -0.0025, -0.1272, -0.2257, -0.0322,\n",
            "          0.0969,  0.0488, -0.2382, -0.1239,  0.0217, -0.2581, -0.4165,  0.0517,\n",
            "          0.0493, -0.3650,  0.0256, -0.2873, -0.0199,  0.0434],\n",
            "        [-0.1981,  0.7632, -0.1224,  0.5031,  0.0348, -0.0617,  0.0894,  0.2686,\n",
            "          0.0676,  0.4718,  0.0082,  0.0902, -0.0531, -0.1083,  0.0932, -0.1313,\n",
            "         -0.0885, -0.1909, -0.1972, -0.2187, -0.1165, -0.2670, -0.1883, -0.1903,\n",
            "          0.0418, -0.0389, -0.1279, -0.1007, -0.0740, -0.0261]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor(2.8970, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1d) Validate your model\n",
        "\n",
        "- Show that the model is not overfitting\n",
        "- How does your model perform ?"
      ],
      "metadata": {
        "id": "cIAwvLE7RKmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ciDEi2W6oPhr"
      },
      "outputs": [],
      "source": [
        "# define model, optimizer, criterion and number of training epochs\n",
        "# *****START CODE\n",
        "\n",
        "model = ConvNet(3,3, final_images = 16)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 1\n",
        "confusion_matrix = tnt.meter.ConfusionMeter(30) \n",
        "confusion_matrix.reset()\n",
        "# *****END CODE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm \n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ##TRAINING##\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    confusion_matrix.reset()\n",
        "\n",
        "    for i, batch, in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "        img_batch, lbl_batch = batch\n",
        "\n",
        "        ##implement the forward and backward backpropagation\n",
        "        # *****START CODE\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # *****END CODE\n",
        "\n",
        "        # log the training loss at each batch\n",
        "        wandb.log({\"train_loss\":loss.item()})\n",
        "        confusion_matrix.add(outputs.data.squeeze(), lbl_batch.long())\n",
        "\n",
        "    train_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
        "\n",
        "    ##VALIDATION##\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    confusion_matrix.reset()\n",
        "\n",
        "    for i, batch, in enumerate(val_dataloader):\n",
        "        img_batch, lbl_batch = batch\n",
        "   \n",
        "        ##pass the images to the model and calculate the loss\n",
        "        # *****START CODE\n",
        "        with torch.no_grad():\n",
        "          outputs=model(img_batch.float())\n",
        "          loss=criterion(outputs, lbl_batch.long())\n",
        "        # *****END CODE\n",
        "\n",
        "        confusion_matrix.add(outputs.data.squeeze(), lbl_batch.long())\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "    val_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
        "    val_loss_mean = np.mean(val_losses)\n",
        "\n",
        "    # log the train & val accuracy and the val loss at each epoch\n",
        "    wandb.log({\"train_acc\":train_acc, \"val_acc\":val_acc, \"val_loss\":val_loss_mean})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOV-WsrWTzx7",
        "outputId": "9065e443-fffc-4909-cd96-0b9af51ba421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|| 4735/5000 [27:27<01:32,  2.88it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1e) Try to optimize hyperparameters, does it improve the performance of your model ?\n",
        "Anwser with a graph and comment on the result."
      ],
      "metadata": {
        "id": "J7B9gOlwbYny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's decrease the learning rate\n",
        "\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "qDWWHnFXLPYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k5ePcF28dUMv",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model and validate it after each epoch.\n",
        "# *****START CODE\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "total_train_losses = []\n",
        "total_val_losses = []\n",
        "\n",
        "for epoch in range(1,epochs+1):\n",
        "    ##TRAINING##\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    confusion_matrix.reset()\n",
        "\n",
        "    for i, batch, in enumerate(tqdm(train_dataloader)):\n",
        "        img_batch, lbl_batch = batch\n",
        "\n",
        "        ##implement the forward and backward backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(img_batch.float())\n",
        "        loss=criterion(outputs, lbl_batch.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        confusion_matrix.add(outputs.data.squeeze(), lbl_batch.long())\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, epochs, i, len(train_dataloader),100.*i/len(train_dataloader), loss.item()))\n",
        "\n",
        "    \n",
        "\n",
        "    train_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
        "        train_loss_mean = np.mean(train_losses)\n",
        "        total_train_losses.append(train_loss_mean)\n",
        "\n",
        "\n",
        "     ##VALIDATION##\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    confusion_matrix.reset()\n",
        "\n",
        "    for i, batch, in enumerate(tqdm(val_dataloader)):\n",
        "        img_batch, lbl_batch = batch\n",
        "   \n",
        "        ##pass the images to the model and calculate the loss\n",
        "        # *****START CODE\n",
        "        with torch.no_grad():\n",
        "          outputs=model(img_batch.float())\n",
        "          loss=criterion(outputs, lbl_batch.long())\n",
        "        # *****END CODE\n",
        "\n",
        "        confusion_matrix.add(outputs.data.squeeze(), lbl_batch.long())\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "    print('Confusion Matrix:')\n",
        "    print(confusion_matrix.conf)\n",
        "\n",
        "    val_acc=(np.trace(confusion_matrix.conf)/float(np.ndarray.sum(confusion_matrix.conf))) *100\n",
        "    val_loss_mean = np.mean(val_losses)\n",
        "    total_val_losses.append(val_loss_mean)\n",
        "\n",
        "    print('TRAIN_LOSS: ', '%.3f' % train_loss_mean, 'TRAIN_ACC: ', '%.3f' % train_acc)\n",
        "    print('VAL_LOSS: ', '%.3f' % val_loss_mean, 'VAL_ACC: ', '%.3f' % val_acc)\n",
        "\n",
        "    write_results(save_folder, epoch, train_acc, val_acc, train_loss_mean, val_loss_mean)\n",
        "\n",
        "    torch.save(model.state_dict(), save_folder + '/model_{}.pt'.format(epoch))\n",
        "\n",
        "save_graph(total_train_losses, total_val_losses, epochs, save_folder)\n"
      ],
      "metadata": {
        "id": "e26RnrNULPYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test pour savoir si ca marche bien ou non "
      ],
      "metadata": {
        "trusted": true,
        "id": "_srvNVlmLPYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1f) Get an intermediate layer from your convolutional neural network and visualize what patterns the network has learned\n",
        "*   Complete the following code that visualizes the patterns of the network\n",
        "*   Write a small description commenting on the visualized maps. What do you observe in the different visualizations of the feature maps?"
      ],
      "metadata": {
        "id": "1Kp8nRiGRKmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The intermediate layer you should visualize:\n",
        "print('My intermediate layer to visualize is: %s'%(my_architecture_dict['visualize']))"
      ],
      "metadata": {
        "id": "jSSGZEoFVm-k",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from skimage import io\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "##function for printing the loss during optimization\n",
        "def write_flush(text, stream=sys.stdout):\n",
        "    stream.write(text)\n",
        "    stream.flush()\n",
        "    return\n",
        "\n",
        "## Number of feature maps in the intermediate layer that you have chosen. \n",
        "# *****START CODE\n",
        "n_conv =   # e.g 64\n",
        "# *****END CODE\n",
        "\n",
        "## Size of visualised filter.\n",
        "img_size = 32\n",
        "\n",
        "##load your optimal model\n",
        "# *****START CODE\n",
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load('drive/..../model.pt')) \n",
        "# *****END CODE\n",
        "\n",
        "## Create a submodel, until the intermediate layer of your choice.\n",
        "## Hint: Use model.#name# to create the succession of layers, where #name#\n",
        "## stands for the layer names that you defined in the initialization function \n",
        "## of your model.\n",
        "# *****START CODE\n",
        "submodel = nn.Sequential(\n",
        "\n",
        "    \n",
        ")\n",
        "# *****END CODE\n",
        "\n",
        "## Put submodel in eval mode.\n",
        "submodel.eval()\n",
        "\n",
        "## Tensor to visualised filters. \n",
        "img_stack = torch.zeros((n_conv, 3, img_size, img_size))\n",
        "\n",
        "## Number of epochs to run for every filter. \n",
        "# *****START CODE\n",
        "n_epochs_per_filt =   #e.g 30\n",
        "# *****END CODE\n",
        "\n",
        "## Visualise every convolution. \n",
        "for c in range(n_conv):\n",
        "    ## Initialise with random image. \n",
        "    img = torch.rand(1, 3, img_size, img_size).float()\n",
        "\n",
        "    ## Turn on gradient calculation on the image\n",
        "    # *****START CODE\n",
        "\n",
        "    # *****END CODE\n",
        "\n",
        "    ## Define optimizer.\n",
        "    # *****START CODE\n",
        "    \n",
        "    # *****END CODE\n",
        "    \n",
        "    for f in range(n_epochs_per_filt):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ## Feedforward propagation\n",
        "        ## Hint: In order to find the loss, compupte the negative of the activation of the hidden layer. \n",
        "        ## The objective is to produce an input image which maximizes the activation \n",
        "        ## of neurons in a particular hidden layer. \n",
        "        # *****START CODE\n",
        "        \n",
        "        \n",
        "        \n",
        "        # *****END CODE\n",
        "        write_flush('\\rFilter %d. Epoch %d. Loss = %.4f'%(c, f+1, loss.item()))\n",
        "\n",
        "    write_flush('\\n')\n",
        "    img_stack[c, :, :, :] = img[0].detach()\n",
        "\n",
        "## Make grid out of visualized filters. \n",
        "##Here you may have to adjust the properties of vutils.make_grid, depending on your needs. \n",
        "##For example, you may need to change the number of rows.\n",
        "G = vutils.make_grid(img_stack, nrow=8, normalize=True, padding=1).permute(1,2,0).numpy()\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(G)\n",
        "plt.axis('equal')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xk4FadJSRKmG",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1g) Use GradCAM algorithm to visualize the saliency maps of your trained model at the same intermediate layer\n",
        "*   Install pytorch grad cam package if needed (https://github.com/jacobgil/pytorch-grad-cam)\n",
        "*   Complete the following code that visualizes GradCAM heatmaps on an input image from your model\n",
        "*   Try on several input images / classes. \n",
        "*   Write a small description commenting on the visualized heatmaps. "
      ],
      "metadata": {
        "id": "4dfeLUNQVm-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pytorch grad cam package\n",
        "'''UNCOMMENT IF NEEDED (using google colab for example)\n",
        "! pip install grad-cam\n",
        "'''\n"
      ],
      "metadata": {
        "id": "jkXGgb11Vm-l",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "use_cuda = True\n",
        "\n",
        "# *****START CODE\n",
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load('drive/..../model.pt'))\n",
        "\n",
        "# Get your intermediate layer\n",
        "target_layers = [model. ...]\n",
        "\n",
        "rgb_img = \n",
        "input_tensor = # Create an input tensor from your image for your model..\n",
        "# Note: input_tensor can be a batch tensor with several images!\n",
        "target_category = \n",
        "# *****END CODE\n",
        "\n",
        "# Construct the CAM object once, and then re-use it on many images:\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
        "\n",
        "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)\n",
        "\n",
        "# In this example grayscale_cam has only one image in the batch:\n",
        "grayscale_cam = grayscale_cam[0, :]\n",
        "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "# Plot figure\n",
        "plt.figure()\n",
        "plt.imshow(visualization)"
      ],
      "metadata": {
        "id": "FU7OPn3cVm-l",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2 - Train on geometrical shapes"
      ],
      "metadata": {
        "id": "o3QK7dhJRKmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function 'generate_a_triangle' produces images depicting random triangles along with the (x,y) coordinates of the vertices. Create a convolutional neural network that receives as input the triangle image and predicts the corresponding (x,y) coordinates of the triangle's vertices. \n",
        "*  Read and understand the following code"
      ],
      "metadata": {
        "id": "-yudhcXrRKmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "# On some implementations of matplotlib, you may need to change this value\n",
        "IMAGE_SIZE = 72\n",
        "\n",
        "def generate_a_drawing(figsize, U, V):\n",
        "    fig = plt.figure(figsize=(figsize,figsize))\n",
        "    ax = plt.subplot(111)\n",
        "    plt.axis('Off')\n",
        "    ax.set_xlim(0,figsize)\n",
        "    ax.set_ylim(0,figsize)\n",
        "    ax.fill(U, V, \"k\")\n",
        "    fig.canvas.draw()\n",
        "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
        "    imdata = imdata + np.random.random(imdata.size)\n",
        "    plt.close(fig)\n",
        "    return imdata\n",
        "\n",
        "def generate_a_triangle():\n",
        "    figsize = 1.0\n",
        "    U = np.random.random(3)\n",
        "    V = np.random.random(3)\n",
        "    imdata = generate_a_drawing(figsize, U, V)\n",
        "    return [imdata, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
        "\n",
        "[im, v] = generate_a_triangle()\n",
        "plt.imshow(im.reshape(IMAGE_SIZE,IMAGE_SIZE), cmap='gray')\n",
        "\n",
        "def generate_dataset_regression(nb_samples):\n",
        "    # Getting im_size:\n",
        "    im_size = generate_a_triangle()[0].shape[0]\n",
        "    X = np.zeros([nb_samples,im_size])\n",
        "    Y = np.zeros([nb_samples, 6])\n",
        "    print('Creating data:')\n",
        "    for i in range(nb_samples):\n",
        "        if i % 10 == 0:\n",
        "            print(i)\n",
        "        [X[i], Y[i]] = generate_a_triangle()\n",
        "    X = X / 255\n",
        "    return [X, Y]\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_prediction(x, y):\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    I = x.reshape((IMAGE_SIZE,IMAGE_SIZE))\n",
        "    ax.imshow(I, extent=[-0.15,1.15,-0.15,1.15],cmap='gray')\n",
        "    ax.set_xlim([0,1])\n",
        "    ax.set_ylim([0,1])\n",
        "\n",
        "    xy = y.reshape(3,2)\n",
        "    tri = patches.Polygon(xy, closed=True, fill = False, edgecolor = 'r', linewidth = 5, alpha = 0.5)\n",
        "    ax.add_patch(tri)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def generate_test_set_regression():\n",
        "    np.random.seed(42)\n",
        "    [X_test, Y_test] = generate_dataset_regression(300)\n",
        "    return [X_test, Y_test]"
      ],
      "metadata": {
        "id": "aptobJOZbRZd",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2a) Use function 'generate_dataset_regression' to create the dataset. Split the dataset to training and validation parts."
      ],
      "metadata": {
        "id": "clB8r3jMRKmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##generate dataset\n",
        "# *****START CODE\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "6Y7mW83fRKmJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##split the dataset to training and validation parts\n",
        "# *****START CODE\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "xIwVanB4RKmK",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.295512Z",
          "iopub.status.idle": "2022-12-14T14:53:20.296180Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.295882Z",
          "shell.execute_reply": "2022-12-14T14:53:20.295908Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2b) Use function 'generate_test_set' to create the testing dataset."
      ],
      "metadata": {
        "id": "NEoZyhgZRKmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##generate test dataset\n",
        "# *****START CODE\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "PE6e3nszRKmK",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.297733Z",
          "iopub.status.idle": "2022-12-14T14:53:20.298463Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.298175Z",
          "shell.execute_reply": "2022-12-14T14:53:20.298200Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2c) Create your own convolutional neural network.\n",
        "* Begin with the previous exercise model architecture\n",
        "* Optimize the architecture to perform well on predicting the different coordinates"
      ],
      "metadata": {
        "id": "tcsDj8eQRKmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# *****START CODE\n",
        "class ConvNetR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetR, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "hQYXQV5LRKmL",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.301455Z",
          "iopub.status.idle": "2022-12-14T14:53:20.302789Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.302489Z",
          "shell.execute_reply": "2022-12-14T14:53:20.302518Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2d) Define learning rate, model, optimizer, criterion and number of epochs."
      ],
      "metadata": {
        "id": "U6PxmyfqRKmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "lr = \n",
        "model = \n",
        "optimizer = \n",
        "criterion = \n",
        "epochs = \n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "vS9LIDmlRKmM",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.304202Z",
          "iopub.status.idle": "2022-12-14T14:53:20.304766Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.304463Z",
          "shell.execute_reply": "2022-12-14T14:53:20.304497Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2e) What criterion did you choose and why?\n",
        "* Write a small description for the loss function that you want to use for this specific problem.\n",
        "* What was your intuition for using this loss?"
      ],
      "metadata": {
        "id": "JNtKYgzTRKmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2f) Train your model and validate it at the end of each epoch.\n",
        "* Similarly to the previous question train and validate your network for each epoch\n",
        "* Write a small description on how you decide which is the optimal epoch\n",
        "* Use this epoch and evaluate your model on the test set\n",
        "* Visualise some predictions using the function 'visualize_prediction'\n",
        "* What do you observe?"
      ],
      "metadata": {
        "id": "HmjN0W-KRKmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "\n",
        "\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "VZfRftoFRKmN",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.306222Z",
          "iopub.status.idle": "2022-12-14T14:53:20.306904Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.306580Z",
          "shell.execute_reply": "2022-12-14T14:53:20.306622Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2g) Think and implement a preprocessing step that can boost the accuracy of your network"
      ],
      "metadata": {
        "id": "zTCMv88pRKmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *****START CODE\n",
        "\n",
        "\n",
        "\n",
        "# *****END CODE"
      ],
      "metadata": {
        "id": "jTqLTm8LRKmN",
        "execution": {
          "iopub.status.busy": "2022-12-14T14:53:20.308652Z",
          "iopub.status.idle": "2022-12-14T14:53:20.309416Z",
          "shell.execute_reply.started": "2022-12-14T14:53:20.309202Z",
          "shell.execute_reply": "2022-12-14T14:53:20.309224Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3\n",
        "Answer these generic questions:"
      ],
      "metadata": {
        "id": "qmogb4BZqanY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3a) What is a metric? What is a loss? What is the difference between both?"
      ],
      "metadata": {
        "id": "UI7zK3GOqiPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "Fse981-xqsaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b) Why deep learning models are difficult to understand even on a particular prediction?"
      ],
      "metadata": {
        "id": "LEPKyXQzqu0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "zkE-FQ3aq_Pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3c) What is \"out of domain data\"?"
      ],
      "metadata": {
        "id": "nB17ceedrBvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "GSxTeaBbrN39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3d) Name five tasks where Deep Learning models are the state-of-the-art:\n",
        "For example: Folding proteins in Biology"
      ],
      "metadata": {
        "id": "gW4zn1h6rO8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "26X2qPH6ruN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3e)What is an activation function and what is it used for in Deep Learning models?"
      ],
      "metadata": {
        "id": "z9aeE0ikrvUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer:"
      ],
      "metadata": {
        "id": "pIgnFkHGtA-k"
      }
    }
  ]
}